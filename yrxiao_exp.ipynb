{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xla:0',\n",
       " 'xla:1',\n",
       " 'xla:2',\n",
       " 'xla:3',\n",
       " 'xla:4',\n",
       " 'xla:5',\n",
       " 'xla:6',\n",
       " 'xla:7',\n",
       " 'xla:8',\n",
       " 'xla:9',\n",
       " 'xla:10',\n",
       " 'xla:11',\n",
       " 'xla:12',\n",
       " 'xla:13',\n",
       " 'xla:14',\n",
       " 'xla:15',\n",
       " 'xla:16',\n",
       " 'xla:17',\n",
       " 'xla:18',\n",
       " 'xla:19',\n",
       " 'xla:20',\n",
       " 'xla:21',\n",
       " 'xla:22',\n",
       " 'xla:23',\n",
       " 'xla:24',\n",
       " 'xla:25',\n",
       " 'xla:26',\n",
       " 'xla:27',\n",
       " 'xla:28',\n",
       " 'xla:29',\n",
       " 'xla:30',\n",
       " 'xla:31']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xm.get_xla_supported_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trunc_normal_ reproduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 22:08:11.000524:  212750  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-01 22:08:11.000526:  212750  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.13.72.0+78a426937/MODULE_17120691043056328803+d41d8cd9/model.neff. Exiting with a successfully compiled graph.\n",
      "Parameter containing:\n",
      "tensor([[ 0.0552, -0.1549, -0.0455,  ..., -0.1197, -0.1469, -0.0273],\n",
      "        [ 0.0421, -0.0083,  0.0758,  ...,  0.1315,  0.1711,  0.0695],\n",
      "        [-0.1300, -0.1669, -0.0734,  ...,  0.1483,  0.0258, -0.0425],\n",
      "        ...,\n",
      "        [-0.0146,  0.0533, -0.1747,  ..., -0.0572,  0.1351,  0.0212],\n",
      "        [-0.0631,  0.1442,  0.0390,  ...,  0.0817, -0.0955, -0.0974],\n",
      "        [-0.0907, -0.1105, -0.1150,  ...,  0.1622,  0.0531, -0.1762]],\n",
      "       device='xla:0', requires_grad=True)\n",
      "2024-07-01 22:08:11.000664:  212750  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-01 22:08:11.000667:  212750  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.13.72.0+78a426937/MODULE_10246491667705214752+d41d8cd9/model.neff. Exiting with a successfully compiled graph.\n",
      "Parameter containing:\n",
      "tensor([[0.5303, 0.5303, 0.5303,  ..., 0.5303, 0.5303, 0.5303],\n",
      "        [0.5303, 0.5303, 0.5303,  ..., 0.5303, 0.5303, 0.5303],\n",
      "        [0.5303, 0.5303, 0.5303,  ..., 0.5303, 0.5303, 0.5303],\n",
      "        ...,\n",
      "        [0.5303, 0.5303, 0.5303,  ..., 0.5303, 0.5303, 0.5303],\n",
      "        [0.5303, 0.5303, 0.5303,  ..., 0.5303, 0.5303, 0.5303],\n",
      "        [0.5303, 0.5303, 0.5303,  ..., 0.5303, 0.5303, 0.5303]],\n",
      "       device='xla:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "from torch import nn\n",
    "import math\n",
    "dim = 32\n",
    "std = 1.0 / math.sqrt(dim)\n",
    "# device=\"xla:0\"\n",
    "# device='cuda:0'\n",
    "device=xm.xla_device()\n",
    "in_proj = nn.Linear(32, 64, bias=False, device=device)\n",
    "print(in_proj.weight)\n",
    "torch.nn.init.trunc_normal_(in_proj.weight, std=std, a=-3 * std, b=3 * std)\n",
    "print(in_proj.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2, 32, device=device, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = in_proj(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 22:14:00.000004:  212750  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-01 22:14:00.000007:  212750  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/d773e7a6-24c9-425b-866b-4a630b8706e3/model.MODULE_13899153033736678188+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/d773e7a6-24c9-425b-866b-4a630b8706e3/model.MODULE_13899153033736678188+d41d8cd9.neff --verbose=35\n",
      ".\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282],\n",
       "        [8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943]], device='xla:0', grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.rand(2, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.L1Loss()\n",
    "d = loss(b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 22:14:07.000258:  212750  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-01 22:14:07.000261:  212750  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/78141499-4c41-45e3-b68e-8ff7c43921e1/model.MODULE_317728922451237312+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/78141499-4c41-45e3-b68e-8ff7c43921e1/model.MODULE_317728922451237312+d41d8cd9.neff --verbose=35\n",
      ".\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656,\n",
       "         0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656,\n",
       "         0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656,\n",
       "         0.2656, 0.2656, 0.2656, 0.2656, 0.2656],\n",
       "        [0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656,\n",
       "         0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656,\n",
       "         0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656,\n",
       "         0.2656, 0.2656, 0.2656, 0.2656, 0.2656]], device='xla:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SwiGLU-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch_xla.core.xla_model as xm\n",
    "class Params:\n",
    "    te_device = xm.xla_device()\n",
    "    dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwiGLUTorch(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, args: Params = Params, bias=True):\n",
    "        super().__init__()\n",
    "        self.w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias, device=args.te_device)\n",
    "        # self.w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias)\n",
    "        self.w3 = nn.Linear(hidden_dim, out_dim, bias=bias, device=args.te_device)\n",
    "        # self.w3 = nn.Linear(hidden_dim, out_dim, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate, x = self.w12(x).chunk(2, dim=-1)\n",
    "        x = F.silu(gate) * x\n",
    "        return self.w3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Params()\n",
    "hidden_dim = 256 * ((int(2 * 4 * args.dim / 3) + 256 - 1) // 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed_forward = SwiGLUTorch(args.dim, hidden_dim, args.dim, bias=False)\n",
    "feed_forward = SwiGLUTorch(args.dim, hidden_dim, args.dim, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.rand(2, args.dim, device=args.te_device, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_res = feed_forward(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:17:43.000223:  264768  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:17:43.000225:  264768  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/f6e4c1d2-3346-42ea-97c4-4f33504117cd/model.MODULE_13096779559885804376+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/f6e4c1d2-3346-42ea-97c4-4f33504117cd/model.MODULE_13096779559885804376+d41d8cd9.neff --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "tensor([[-5.4396e-02,  2.4788e-03, -3.6057e-02, -1.0108e-01, -1.1356e-02,\n",
      "          2.1630e-01,  5.1195e-02,  2.5060e-02, -1.2509e-02, -2.9625e-02,\n",
      "         -1.6905e-02, -8.6524e-03,  8.2070e-02, -1.3243e-02,  5.1400e-02,\n",
      "          1.2978e-02, -8.5661e-02, -1.2061e-02,  1.2263e-02, -6.8452e-02,\n",
      "         -5.0165e-02,  3.9816e-02,  4.1906e-02, -1.1900e-01, -1.8282e-02,\n",
      "          6.6551e-03,  2.8953e-02,  1.3302e-02,  1.0320e-01,  1.7242e-02,\n",
      "         -4.8870e-02, -5.7309e-02,  3.0372e-02, -8.2271e-02, -1.1382e-03,\n",
      "          8.1762e-02,  7.9631e-02, -4.7795e-03, -1.7675e-02, -1.9920e-02,\n",
      "         -1.5851e-02, -7.7713e-04,  5.1037e-03, -4.3835e-02, -1.7313e-03,\n",
      "          2.7527e-03, -1.2865e-01, -4.2344e-02, -8.6313e-02, -4.5887e-02,\n",
      "         -7.7144e-02,  2.5151e-02, -5.3777e-02,  7.1058e-02,  7.8367e-02,\n",
      "          5.2203e-02, -7.2707e-02,  1.5272e-02, -2.1821e-02, -1.0093e-02,\n",
      "         -6.2742e-02, -8.1296e-02,  3.6875e-02,  1.4001e-02],\n",
      "        [-6.0170e-02, -2.1390e-02, -3.5301e-02, -8.1397e-03, -5.9280e-04,\n",
      "          9.2743e-02,  4.0837e-02, -3.6541e-02, -2.1321e-02, -3.0524e-02,\n",
      "         -5.5957e-02,  1.3168e-02,  5.3979e-02, -3.8231e-03,  6.9416e-03,\n",
      "          1.8016e-02, -3.4578e-02, -8.8645e-03,  6.2017e-03, -1.8485e-02,\n",
      "         -4.4248e-02,  3.1927e-02, -3.4785e-02, -6.0712e-02,  2.9858e-05,\n",
      "          5.9383e-02,  6.0506e-02,  5.3251e-02,  3.4022e-02,  4.7258e-03,\n",
      "         -2.3585e-02, -4.8863e-02,  2.8277e-02,  1.2446e-02,  5.5191e-02,\n",
      "          7.4914e-02,  7.4106e-02, -1.0546e-02, -2.5671e-02, -6.0683e-02,\n",
      "         -1.8857e-02,  2.7136e-02, -2.0723e-02,  3.0882e-02, -6.4444e-02,\n",
      "          3.9917e-04, -5.2631e-02, -3.0724e-02, -8.8617e-02, -4.5381e-02,\n",
      "         -1.1280e-02, -2.5595e-02, -1.6588e-02,  2.8029e-02,  1.0146e-01,\n",
      "          1.0246e-02, -6.1897e-02,  1.5295e-02, -6.1482e-03, -2.8196e-02,\n",
      "         -8.8946e-02, -5.4503e-02,  3.1825e-02,  4.8745e-03]], device='xla:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First minimal block - confirmed bug existed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:21:43.000300:  264768  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:21:43.000302:  264768  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/d3665e76-36fc-4959-81cc-21acafe435a9/model.MODULE_15793982884432442560+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/d3665e76-36fc-4959-81cc-21acafe435a9/model.MODULE_15793982884432442560+d41d8cd9.neff --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "tensor([[ 0.0041,  0.0943, -0.0168,  0.0420, -0.0077,  0.0305, -0.0181,  0.0230,\n",
      "         -0.0666, -0.0475, -0.0149,  0.0162, -0.0127,  0.0305, -0.0040,  0.0311,\n",
      "         -0.0414, -0.1199, -0.0031, -0.0465,  0.0716, -0.0505, -0.0013, -0.0252,\n",
      "         -0.0435, -0.0330, -0.0317, -0.0164,  0.0551, -0.0207, -0.0724, -0.0230,\n",
      "          0.0215, -0.0102, -0.0254,  0.0936,  0.0846,  0.0255,  0.0509, -0.0537,\n",
      "         -0.0049,  0.0553, -0.0336, -0.0329, -0.0538,  0.0217,  0.0841, -0.0208,\n",
      "          0.0110, -0.0219, -0.0235, -0.0174, -0.0643, -0.0739, -0.0518,  0.0979,\n",
      "          0.0207, -0.0692, -0.0601,  0.0003,  0.0245,  0.0389,  0.0544,  0.0928],\n",
      "        [ 0.0262,  0.0959, -0.0118, -0.0084,  0.0285, -0.0084,  0.0079, -0.0306,\n",
      "         -0.0629, -0.0543,  0.0009,  0.0084,  0.0425, -0.0310,  0.0742,  0.0108,\n",
      "         -0.0041, -0.1179,  0.0056, -0.0739,  0.0185,  0.0002,  0.0131,  0.0051,\n",
      "          0.0553, -0.0336,  0.0083, -0.0349,  0.0406,  0.0747, -0.0150,  0.0320,\n",
      "         -0.0129, -0.0415,  0.0203,  0.0321,  0.0994,  0.0543,  0.0125, -0.0603,\n",
      "         -0.0287,  0.0397, -0.0234,  0.0204,  0.0084,  0.0022,  0.1035,  0.0199,\n",
      "         -0.0304, -0.0949, -0.0401, -0.0511,  0.0007, -0.0610, -0.0304,  0.0530,\n",
      "          0.0349, -0.0339, -0.0257, -0.0178,  0.0898,  0.0818,  0.0918,  0.0817]],\n",
      "       device='xla:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch_xla.core.xla_model as xm\n",
    "class Params:\n",
    "    te_device = xm.xla_device()\n",
    "    dim = 64\n",
    "\n",
    "\n",
    "class SwiGLUTorch(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, args: Params = Params, bias=True):\n",
    "        super().__init__()\n",
    "        self.w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias, device=args.te_device)\n",
    "        self.w3 = nn.Linear(hidden_dim, out_dim, bias=bias, device=args.te_device)\n",
    "    def forward(self, x):\n",
    "        gate, x = self.w12(x).chunk(2, dim=-1)\n",
    "        x = F.silu(gate) * x\n",
    "        return self.w3(x)\n",
    "\n",
    "\n",
    "args = Params()\n",
    "hidden_dim = 256 * ((int(2 * 4 * args.dim / 3) + 256 - 1) // 256)\n",
    "\n",
    "# feed_forward = SwiGLUTorch(args.dim, hidden_dim, args.dim, bias=False)\n",
    "feed_forward = SwiGLUTorch(args.dim, hidden_dim, args.dim, bias=True)\n",
    "\n",
    "input_data = torch.rand(2, args.dim, device=args.te_device, requires_grad=True)\n",
    "\n",
    "out_res = feed_forward(input_data)\n",
    "\n",
    "print(out_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:21:58.000089:  264768  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:21:58.000091:  264768  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/db98c2ca-6d7e-4c6a-bac7-1709e056f91e/model.MODULE_12445586597400423240+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/db98c2ca-6d7e-4c6a-bac7-1709e056f91e/model.MODULE_12445586597400423240+d41d8cd9.neff --verbose=35\n",
      ".root = /usr/lib/python3.10/multiprocessing/process.py\n",
      "root = /usr/lib/python3.10/multiprocessing\n",
      "root = /usr/lib/python3.10\n",
      "root = /usr/lib\n",
      "root = /usr\n",
      "\n",
      "2024-07-02 16:22:00.000153:  264768  ERROR ||NEURON_CC_WRAPPER||: Failed compilation with ['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/db98c2ca-6d7e-4c6a-bac7-1709e056f91e/model.MODULE_12445586597400423240+d41d8cd9.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/db98c2ca-6d7e-4c6a-bac7-1709e056f91e/model.MODULE_12445586597400423240+d41d8cd9.neff', '--verbose=35']: 2024-07-02T16:21:59Z [TEN404] Internal tensorizer error - Please open a support ticket at https://github.com/aws-neuron/aws-neuron-sdk/issues/new\n",
      "\n",
      "2024-07-02 16:22:00.000154:  264768  ERROR ||NEURON_CC_WRAPPER||: Compilation failed for /tmp/ubuntu/neuroncc_compile_workdir/db98c2ca-6d7e-4c6a-bac7-1709e056f91e/model.MODULE_12445586597400423240+d41d8cd9.hlo_module.pb after 0 retries.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch_xla.core.xla_model as xm\n",
    "class Params:\n",
    "    te_device = xm.xla_device()\n",
    "    dim = 64\n",
    "\n",
    "\n",
    "class SwiGLUTorch(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, args: Params = Params, bias=True):\n",
    "        super().__init__()\n",
    "        self.w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias, device=args.te_device)\n",
    "        self.w3 = nn.Linear(hidden_dim, out_dim, bias=bias, device=args.te_device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate, x = self.w12(x).chunk(2, dim=-1)\n",
    "        x = F.silu(gate) * x\n",
    "        return self.w3(x)\n",
    "\n",
    "\n",
    "args = Params()\n",
    "hidden_dim = 256 * ((int(2 * 4 * args.dim / 3) + 256 - 1) // 256)\n",
    "\n",
    "feed_forward = SwiGLUTorch(args.dim, hidden_dim, args.dim, bias=False)\n",
    "# feed_forward = SwiGLUTorch(args.dim, hidden_dim, args.dim, bias=True)\n",
    "\n",
    "input_data = torch.rand(2, args.dim, device=args.te_device, requires_grad=True)\n",
    "\n",
    "out_res = feed_forward(input_data)\n",
    "\n",
    "print(out_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize the block - bias=False to identify the buggy place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch_xla.core.xla_model as xm\n",
    "class Params:\n",
    "    te_device = xm.xla_device()\n",
    "    dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 20:50:10.000477:  284431  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 20:50:10.000479:  284431  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.13.72.0+78a426937/MODULE_4744642293627985264+d41d8cd9/model.neff. Exiting with a successfully compiled graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0384, device='xla:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "args = Params()\n",
    "in_dim = args.dim\n",
    "hidden_dim = 256 * ((int(2 * 4 * args.dim / 3) + 256 - 1) // 256)\n",
    "out_dim = args.dim\n",
    "\n",
    "bias = False\n",
    "# bias = True\n",
    "\n",
    "w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias, device=args.te_device)\n",
    "# w3 = nn.Linear(hidden_dim, out_dim, bias=bias, device=args.te_device)\n",
    "\n",
    "input_data = torch.rand(2, args.dim, device=args.te_device, requires_grad=True)\n",
    "x = input_data\n",
    "\n",
    "# Feed forward\n",
    "gate, x = w12(x).chunk(2, dim=-1)\n",
    "# x = F.silu(gate) * x\n",
    "# out_res = w3(x)\n",
    "\n",
    "print(x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gate res: 2024-07-02 20:50:10.000634:  284431  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 20:50:10.000637:  284431  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.13.72.0+78a426937/MODULE_12577992882644976145+d41d8cd9/model.neff. Exiting with a successfully compiled graph.\n",
      "tensor(-0.0107, device='xla:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = input_data\n",
    "gate, x = w12(x).chunk(2, dim=-1)\n",
    "gate_res = F.silu(gate)\n",
    "print(\"gate res:\", gate_res[0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 20:50:13.000666:  284431  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 20:50:13.000669:  284431  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.13.72.0+78a426937/MODULE_12477483825163780359+d41d8cd9/model.neff. Exiting with a successfully compiled graph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8417e-02,  5.4682e-01, -4.2049e-01, -5.7221e-02,  6.1046e-02,\n",
       "         -4.0124e-01, -3.8767e-01, -3.9029e-01, -4.8341e-02, -1.8044e-01,\n",
       "          4.7251e-02,  2.4704e-01,  5.0204e-01, -3.4156e-02,  4.7420e-02,\n",
       "          3.9887e-01,  3.3719e-01, -1.7850e-01,  1.6671e-01,  8.6862e-01,\n",
       "         -2.8862e-01, -3.0525e-01, -4.4352e-02,  2.6474e-01,  6.5911e-02,\n",
       "         -6.7675e-02,  2.4921e-01,  1.8104e-01, -1.9953e-01, -4.5766e-02,\n",
       "          9.1586e-02, -1.1842e-01,  8.1991e-02, -9.6470e-02, -1.1874e-01,\n",
       "          3.1664e-01, -5.0548e-01, -5.3778e-01,  2.4745e-01, -6.5174e-01,\n",
       "          4.8625e-02,  5.4527e-02, -1.9364e-02,  2.0371e-02, -3.8894e-01,\n",
       "         -5.9887e-01,  6.6845e-01, -6.1075e-02, -1.3003e-01, -2.3642e-01,\n",
       "         -1.2695e-01,  7.7555e-02, -8.6472e-02, -8.9840e-02, -7.0883e-01,\n",
       "         -1.4807e-01, -5.6849e-01, -8.8331e-02, -4.6134e-01,  1.4206e-01,\n",
       "         -1.0949e-01,  1.6279e-01, -1.4006e-01, -5.8972e-01,  9.7943e-01,\n",
       "         -8.7838e-02,  3.2581e-02, -4.4892e-01,  1.0582e-01,  4.9404e-01,\n",
       "         -3.5195e-01,  3.8500e-01,  1.3740e-01, -2.7634e-01, -5.2680e-01,\n",
       "          4.3835e-02, -1.5733e-01,  2.4896e-01,  3.6147e-01, -1.1157e-02,\n",
       "          5.8448e-01, -4.0594e-01, -1.0742e-01,  6.8023e-02, -1.1322e-02,\n",
       "          4.0569e-01,  3.3181e-02,  8.1652e-02,  2.1153e-01, -1.8348e-01,\n",
       "         -1.0380e-02, -3.6015e-01,  5.9812e-01,  1.4280e-01,  6.0346e-01,\n",
       "         -8.9689e-02,  2.1144e-01, -2.4313e-01,  1.9582e-01, -3.9255e-01,\n",
       "          2.7280e-01,  7.8620e-04,  1.8492e-03,  8.4218e-02,  4.1339e-01,\n",
       "         -1.5050e-01, -5.6531e-01, -1.7394e-01, -3.9389e-01, -3.7189e-01,\n",
       "          2.3782e-01, -1.0663e+00, -3.7445e-01,  2.2008e-01, -1.3717e-01,\n",
       "         -5.7165e-02, -6.4061e-01,  6.3266e-01, -4.0851e-01, -1.5791e-01,\n",
       "         -3.9213e-02, -1.1718e-01,  6.8693e-01, -1.5404e-01,  4.5934e-01,\n",
       "          9.7238e-03,  1.3038e-01, -7.0622e-02, -3.3452e-01,  2.4092e-01,\n",
       "          4.7052e-01,  2.9565e-01, -5.2953e-01,  3.0244e-01, -9.3893e-02,\n",
       "          1.4291e-01, -3.1920e-01,  5.0554e-01, -2.4121e-01,  2.1301e-01,\n",
       "          7.1084e-02, -3.2425e-01, -2.6374e-01,  1.0625e-01, -2.6477e-01,\n",
       "         -4.6130e-01, -2.3150e-01,  2.9737e-01,  2.9077e-03,  5.7961e-02,\n",
       "          6.4639e-01, -4.1803e-01, -2.4622e-01, -9.4490e-03, -1.7568e-01,\n",
       "          3.0318e-01,  6.2804e-03, -1.6370e-02, -2.9843e-01, -2.9505e-01,\n",
       "         -2.0124e-01,  2.3781e-01,  2.0725e-03, -1.8698e-01,  6.5384e-01,\n",
       "         -1.7019e-01,  2.8165e-01, -9.7253e-02, -1.8456e-01,  4.0779e-01,\n",
       "         -1.7706e-01, -2.0756e-01,  3.2758e-01, -2.3533e-01,  5.1443e-01,\n",
       "          8.0892e-01, -1.2733e-01, -1.2949e-01,  3.5377e-01,  4.1337e-02,\n",
       "          4.9342e-02,  1.6189e-01,  1.2220e-01, -1.6353e-01, -1.4286e-01,\n",
       "         -1.1078e-01,  2.5117e-01, -3.2516e-01,  5.3980e-01, -9.2227e-02,\n",
       "          2.5138e-02,  3.2952e-01,  1.7370e-01, -8.4798e-02,  6.6804e-01,\n",
       "          5.0876e-03, -1.6324e-01, -5.8452e-02, -2.6447e-01,  3.8445e-01,\n",
       "         -3.3532e-01,  3.8178e-01,  1.2918e-01,  4.3588e-01,  1.1642e-01,\n",
       "          3.0111e-01,  2.7136e-01, -2.3977e-01,  5.4424e-02,  1.1026e-01,\n",
       "          4.8482e-01,  4.3405e-01,  1.6215e-01,  4.7968e-01,  2.3723e-01,\n",
       "         -3.1240e-01, -2.9257e-01,  3.2583e-01,  8.4048e-02,  3.1557e-01,\n",
       "         -3.2983e-01,  5.1724e-02, -1.5944e-01, -1.4708e-01, -2.3122e-02,\n",
       "         -7.8677e-02,  3.0969e-03, -1.6672e-01,  2.6946e-01, -1.7058e-01,\n",
       "          3.3476e-01,  2.0119e-01,  3.6782e-02,  9.3679e-03,  1.4661e-01,\n",
       "         -2.5400e-01, -4.6935e-01, -1.1335e-01,  1.3865e-01, -6.6670e-01,\n",
       "          1.7064e-01,  6.4566e-01, -6.1115e-01, -8.3650e-01,  1.2661e-01,\n",
       "         -4.3764e-02,  4.4012e-01,  3.1827e-01,  1.6396e-01,  1.4664e-01,\n",
       "         -4.4617e-02, -2.7475e-02, -5.5874e-02,  1.5897e-01, -2.4370e-01,\n",
       "         -3.4272e-01],\n",
       "        [ 9.8391e-02,  4.5961e-01, -2.7901e-02, -1.4663e-01,  2.2937e-01,\n",
       "         -5.3020e-01, -6.5215e-02, -1.9415e-01,  1.6106e-02, -5.1919e-02,\n",
       "         -8.4551e-02,  1.2247e-02,  3.2466e-02, -2.7427e-01,  9.1573e-02,\n",
       "         -1.3736e-01, -2.0626e-01, -1.6506e-01,  1.8796e-01,  8.7237e-01,\n",
       "         -6.1093e-01, -1.8670e-01, -1.2178e-01,  2.2952e-01,  1.5774e-01,\n",
       "         -1.9969e-01,  1.8082e-01, -2.4990e-01, -2.2407e-01,  1.6543e-01,\n",
       "         -2.5818e-01, -5.0982e-01, -2.1453e-01, -1.3966e-01, -1.6187e-01,\n",
       "          2.0617e-01, -7.1570e-01, -4.9237e-01, -2.5305e-02, -3.7545e-01,\n",
       "          1.3991e-01, -1.0055e-01,  1.6021e-01,  2.9656e-01, -2.1936e-01,\n",
       "         -3.8774e-01,  8.5556e-01, -2.9852e-01, -5.7173e-02, -3.5421e-01,\n",
       "         -7.5771e-03,  2.6476e-02, -2.6651e-01, -1.5077e-01, -4.4653e-01,\n",
       "         -3.8189e-01, -1.9201e-01,  5.5016e-02, -8.5021e-02,  1.2001e-01,\n",
       "          3.0174e-01,  2.0331e-01, -2.4088e-01, -5.8010e-01,  9.5210e-01,\n",
       "         -6.2316e-01, -1.6402e-02, -4.2882e-01,  2.6051e-01,  2.8849e-01,\n",
       "         -3.5399e-01,  6.3607e-01, -4.5453e-01,  4.0520e-01, -5.4728e-01,\n",
       "          1.2306e-01, -4.2450e-01,  3.5711e-01,  2.2492e-01, -6.0957e-02,\n",
       "          2.0081e-01, -6.9025e-01,  8.5431e-02, -1.4845e-01, -1.4037e-02,\n",
       "          2.4005e-01, -2.8439e-01,  2.8886e-01,  3.0944e-01, -3.4675e-01,\n",
       "          1.5525e-02, -6.4122e-01,  9.8191e-01,  2.9217e-02,  4.2249e-01,\n",
       "         -4.1828e-01,  3.9514e-01, -2.7800e-01,  4.5423e-02, -3.1990e-01,\n",
       "          1.3525e-01,  5.5397e-02, -3.9422e-01, -1.4750e-01,  6.9000e-02,\n",
       "         -1.2809e-01, -4.4420e-01,  9.8993e-02, -2.2192e-01, -3.4724e-01,\n",
       "         -3.5236e-03, -6.6065e-01, -4.0423e-01, -3.7174e-02, -2.9500e-01,\n",
       "          3.1679e-01, -5.6117e-01,  1.9259e-01,  7.6761e-02, -4.1140e-01,\n",
       "         -3.5950e-03, -6.7955e-01,  3.5548e-01, -4.6649e-01,  1.8651e-01,\n",
       "         -1.1433e-02,  2.1360e-01, -1.3766e-01, -3.2082e-01,  1.3349e-01,\n",
       "         -4.3603e-02,  2.4945e-01, -6.8792e-01,  3.0094e-01,  1.9920e-01,\n",
       "          3.2092e-01, -3.8869e-01,  1.7294e-01,  1.9295e-01,  3.8422e-01,\n",
       "         -7.6775e-02, -1.2824e-01, -1.5824e-01,  1.0479e-01,  9.6070e-02,\n",
       "         -6.7478e-01, -4.8149e-01,  5.3775e-01,  2.3344e-01,  2.3559e-01,\n",
       "          6.8481e-01, -2.5812e-01,  4.6320e-03, -1.1543e-01, -1.5882e-03,\n",
       "          2.6087e-01,  8.3621e-03,  1.2877e-01, -2.0233e-01, -3.3295e-01,\n",
       "         -9.2062e-02, -1.6941e-01,  9.9289e-02,  1.2324e-01,  5.9316e-01,\n",
       "         -2.8186e-01, -2.9399e-03, -3.0329e-01, -3.8079e-02, -1.5330e-01,\n",
       "         -3.1785e-01, -5.5015e-01,  4.0331e-01, -3.1429e-01,  4.4753e-01,\n",
       "          1.0097e+00,  2.3736e-01, -2.0044e-01,  4.7455e-01,  2.7560e-01,\n",
       "          1.6652e-01,  1.0310e-01,  2.9431e-01, -1.9331e-01, -3.6872e-01,\n",
       "         -5.0385e-01,  4.2011e-01, -2.4176e-02,  6.3396e-01, -2.2731e-01,\n",
       "         -1.6919e-01,  5.3623e-01, -7.4489e-02, -1.7769e-01,  3.7966e-01,\n",
       "          2.6051e-01, -2.4867e-01, -7.3188e-02, -2.3818e-01,  6.6113e-01,\n",
       "         -1.1669e-01,  3.8129e-01,  4.1844e-01,  9.7929e-02,  1.8446e-01,\n",
       "          2.5722e-01,  1.6799e-01,  1.0306e-01,  5.8669e-01, -1.6379e-01,\n",
       "          1.0321e-01,  1.1112e-01, -1.3767e-01,  2.5214e-01,  2.6450e-01,\n",
       "         -1.2816e-01,  3.2575e-02,  3.2321e-01, -1.7796e-01,  3.2825e-01,\n",
       "         -1.4035e-01, -3.3566e-02, -2.8149e-01, -1.9418e-02, -5.7109e-01,\n",
       "         -6.9817e-02, -3.9701e-02,  1.7761e-02,  2.8986e-02,  1.0967e-01,\n",
       "          4.1217e-02,  4.0026e-01,  4.2672e-02, -1.7825e-04,  4.3004e-02,\n",
       "          3.5994e-01, -4.8828e-01, -2.6102e-01,  3.1594e-01, -3.9087e-01,\n",
       "          2.7717e-01,  6.1601e-01, -7.2041e-01, -7.5258e-01,  5.7885e-02,\n",
       "          2.5534e-01,  1.1213e+00,  7.9580e-02, -1.1164e-01, -2.2296e-01,\n",
       "          2.8751e-01,  1.3968e-01, -3.9627e-01,  5.2803e-01,  6.0487e-02,\n",
       "         -6.4202e-01]], device='xla:0', grad_fn=<SplitBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_res_before_w3:  2024-07-02 19:45:06.000359:  283884  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 19:45:06.000361:  283884  ERROR ||NEURON_CC_WRAPPER||: Got a cached failed neff at /var/tmp/neuron-compile-cache/neuronxcc-2.13.72.0+78a426937/MODULE_2625073130775174431+d41d8cd9/model.neff. Will skip compilation, please set --retry_failed_compilation for recompilation: \n",
      " Failed compilation with ['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/d80981b3-de32-4fcc-be1e-732b7040a871/model.MODULE_2625073130775174431+d41d8cd9.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/d80981b3-de32-4fcc-be1e-732b7040a871/model.MODULE_2625073130775174431+d41d8cd9.neff', '--verbose=35']: 2024-07-02T16:47:45Z [TEN404] Internal tensorizer error - Please open a support ticket at https://github.com/aws-neuron/aws-neuron-sdk/issues/new\n",
      ".\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "out_res_before_w3 = gate_res * x \n",
    "print(\"out_res_before_w3: \", out_res_before_w3[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_res_before_w3:  2024-07-02 18:55:51.000123:  279728  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 18:55:51.000127:  279728  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/3d3272d8-0368-4f3e-9477-c8357193805f/model.MODULE_4606195053616088037+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/3d3272d8-0368-4f3e-9477-c8357193805f/model.MODULE_4606195053616088037+d41d8cd9.neff --verbose=35\n",
      ".root = /usr/lib/python3.10/multiprocessing/process.py\n",
      "root = /usr/lib/python3.10/multiprocessing\n",
      "root = /usr/lib/python3.10\n",
      "root = /usr/lib\n",
      "root = /usr\n",
      "\n",
      "2024-07-02 18:55:53.000202:  279728  ERROR ||NEURON_CC_WRAPPER||: Failed compilation with ['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/3d3272d8-0368-4f3e-9477-c8357193805f/model.MODULE_4606195053616088037+d41d8cd9.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/3d3272d8-0368-4f3e-9477-c8357193805f/model.MODULE_4606195053616088037+d41d8cd9.neff', '--verbose=35']: 2024-07-02T18:55:53Z [TEN404] Internal tensorizer error - Please open a support ticket at https://github.com/aws-neuron/aws-neuron-sdk/issues/new\n",
      "\n",
      "2024-07-02 18:55:53.000202:  279728  ERROR ||NEURON_CC_WRAPPER||: Compilation failed for /tmp/ubuntu/neuroncc_compile_workdir/3d3272d8-0368-4f3e-9477-c8357193805f/model.MODULE_4606195053616088037+d41d8cd9.hlo_module.pb after 0 retries.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# out_res_before_w3 = gate_res * x \n",
    "# out_res_before_w3 = gate_res + x \n",
    "out_res_before_w3 = torch.mul(gate_res, x)\n",
    "print(\"out_res_before_w3: \", out_res_before_w3[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w12_T = nn.Linear(in_dim, 2 * hidden_dim, bias=True, device=args.te_device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 64]), torch.Size([512]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w12_T.weight.shape, w12_T.bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias=True works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:29:10.000899:  265991  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:29:10.000901:  265991  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/f1a59657-c2bd-48df-9266-c98d0fb02d6a/model.MODULE_13130582528755289296+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/f1a59657-c2bd-48df-9266-c98d0fb02d6a/model.MODULE_13130582528755289296+d41d8cd9.neff --verbose=35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Compiler status PASS\n",
      "tensor([[ 0.0795,  0.0199,  0.0098,  0.0036, -0.0297,  0.0439,  0.0641,  0.0479,\n",
      "         -0.0463, -0.0331, -0.0226,  0.0218, -0.0594, -0.0714, -0.0943, -0.0110,\n",
      "          0.0381,  0.0193, -0.0253, -0.0070, -0.0219,  0.0099,  0.0808, -0.0022,\n",
      "         -0.0886, -0.0090, -0.0910, -0.0522,  0.0207,  0.0209,  0.0953,  0.0139,\n",
      "         -0.0214, -0.0464,  0.0444,  0.0960, -0.0146,  0.0019, -0.0395, -0.1116,\n",
      "          0.0116,  0.0529,  0.0819,  0.0291,  0.0415,  0.0611,  0.0124,  0.0138,\n",
      "         -0.0146, -0.0398,  0.0770,  0.0370,  0.0348,  0.0694,  0.0095, -0.0007,\n",
      "          0.0115,  0.0397,  0.0618, -0.0070, -0.0072,  0.0444,  0.0352,  0.0056],\n",
      "        [ 0.0760, -0.0689, -0.0169,  0.0469, -0.0192,  0.0050,  0.0377,  0.0061,\n",
      "         -0.0644, -0.0557, -0.0811,  0.0475,  0.0372, -0.0131, -0.0621, -0.0388,\n",
      "         -0.0027,  0.0351, -0.0085,  0.0346,  0.0186,  0.0548,  0.0062, -0.0252,\n",
      "         -0.0514, -0.0633, -0.0997, -0.0211,  0.0526,  0.0092,  0.0654,  0.0114,\n",
      "         -0.0215, -0.0839,  0.0131,  0.0583,  0.0273,  0.0406, -0.0226, -0.0656,\n",
      "         -0.0132,  0.0742,  0.0416,  0.0605,  0.0540,  0.0509, -0.0316,  0.0549,\n",
      "          0.0126, -0.0299,  0.0242, -0.0057,  0.0785,  0.0637,  0.0381, -0.0118,\n",
      "         -0.0002,  0.0158, -0.0016,  0.0321,  0.0617,  0.0183,  0.0553,  0.0292]],\n",
      "       device='xla:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Works fine\n",
    "args = Params()\n",
    "in_dim = args.dim\n",
    "hidden_dim = 256 * ((int(2 * 4 * args.dim / 3) + 256 - 1) // 256)\n",
    "out_dim = args.dim\n",
    "\n",
    "bias = True\n",
    "\n",
    "w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias, device=args.te_device)\n",
    "w3 = nn.Linear(hidden_dim, out_dim, bias=bias, device=args.te_device)\n",
    "\n",
    "\n",
    "\n",
    "input_data = torch.rand(2, args.dim, device=args.te_device, requires_grad=True)\n",
    "x = input_data\n",
    "\n",
    "# Feed forward\n",
    "gate, x = w12(x).chunk(2, dim=-1)\n",
    "x = F.silu(gate) * x\n",
    "out_res = w3(x)\n",
    "\n",
    "\n",
    "print(out_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:30:58.000386:  266572  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:30:58.000388:  266572  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/5a269232-1341-4dc8-b8e1-0825636dc043/model.MODULE_5261249125463362669+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/5a269232-1341-4dc8-b8e1-0825636dc043/model.MODULE_5261249125463362669+d41d8cd9.neff --verbose=35\n",
      ".root = /usr/lib/python3.10/multiprocessing/process.py\n",
      "root = /usr/lib/python3.10/multiprocessing\n",
      "root = /usr/lib/python3.10\n",
      "root = /usr/lib\n",
      "root = /usr\n",
      "\n",
      "2024-07-02 16:31:00.000300:  266572  ERROR ||NEURON_CC_WRAPPER||: Failed compilation with ['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/5a269232-1341-4dc8-b8e1-0825636dc043/model.MODULE_5261249125463362669+d41d8cd9.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/5a269232-1341-4dc8-b8e1-0825636dc043/model.MODULE_5261249125463362669+d41d8cd9.neff', '--verbose=35']: 2024-07-02T16:31:00Z [TEN404] Internal tensorizer error - Please open a support ticket at https://github.com/aws-neuron/aws-neuron-sdk/issues/new\n",
      "\n",
      "2024-07-02 16:31:00.000301:  266572  ERROR ||NEURON_CC_WRAPPER||: Compilation failed for /tmp/ubuntu/neuroncc_compile_workdir/5a269232-1341-4dc8-b8e1-0825636dc043/model.MODULE_5261249125463362669+d41d8cd9.hlo_module.pb after 0 retries.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuronx_venv_pytorch_2_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
