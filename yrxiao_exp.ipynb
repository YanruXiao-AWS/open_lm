{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trunc_normal_ reproduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 22:08:11.000524:  212750  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-01 22:08:11.000526:  212750  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.13.72.0+78a426937/MODULE_17120691043056328803+d41d8cd9/model.neff. Exiting with a successfully compiled graph.\n",
      "Parameter containing:\n",
      "tensor([[ 0.0552, -0.1549, -0.0455,  ..., -0.1197, -0.1469, -0.0273],\n",
      "        [ 0.0421, -0.0083,  0.0758,  ...,  0.1315,  0.1711,  0.0695],\n",
      "        [-0.1300, -0.1669, -0.0734,  ...,  0.1483,  0.0258, -0.0425],\n",
      "        ...,\n",
      "        [-0.0146,  0.0533, -0.1747,  ..., -0.0572,  0.1351,  0.0212],\n",
      "        [-0.0631,  0.1442,  0.0390,  ...,  0.0817, -0.0955, -0.0974],\n",
      "        [-0.0907, -0.1105, -0.1150,  ...,  0.1622,  0.0531, -0.1762]],\n",
      "       device='xla:0', requires_grad=True)\n",
      "2024-07-01 22:08:11.000664:  212750  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-01 22:08:11.000667:  212750  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.13.72.0+78a426937/MODULE_10246491667705214752+d41d8cd9/model.neff. Exiting with a successfully compiled graph.\n",
      "Parameter containing:\n",
      "tensor([[0.5303, 0.5303, 0.5303,  ..., 0.5303, 0.5303, 0.5303],\n",
      "        [0.5303, 0.5303, 0.5303,  ..., 0.5303, 0.5303, 0.5303],\n",
      "        [0.5303, 0.5303, 0.5303,  ..., 0.5303, 0.5303, 0.5303],\n",
      "        ...,\n",
      "        [0.5303, 0.5303, 0.5303,  ..., 0.5303, 0.5303, 0.5303],\n",
      "        [0.5303, 0.5303, 0.5303,  ..., 0.5303, 0.5303, 0.5303],\n",
      "        [0.5303, 0.5303, 0.5303,  ..., 0.5303, 0.5303, 0.5303]],\n",
      "       device='xla:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "from torch import nn\n",
    "import math\n",
    "dim = 32\n",
    "std = 1.0 / math.sqrt(dim)\n",
    "# device=\"xla:0\"\n",
    "# device='cuda:0'\n",
    "device=xm.xla_device()\n",
    "in_proj = nn.Linear(32, 64, bias=False, device=device)\n",
    "print(in_proj.weight)\n",
    "torch.nn.init.trunc_normal_(in_proj.weight, std=std, a=-3 * std, b=3 * std)\n",
    "print(in_proj.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2, 32, device=device, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = in_proj(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 22:14:00.000004:  212750  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-01 22:14:00.000007:  212750  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/d773e7a6-24c9-425b-866b-4a630b8706e3/model.MODULE_13899153033736678188+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/d773e7a6-24c9-425b-866b-4a630b8706e3/model.MODULE_13899153033736678188+d41d8cd9.neff --verbose=35\n",
      ".\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282, 7.3282,\n",
       "         7.3282],\n",
       "        [8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943, 8.0943,\n",
       "         8.0943]], device='xla:0', grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.rand(2, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.L1Loss()\n",
    "d = loss(b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-01 22:14:07.000258:  212750  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-01 22:14:07.000261:  212750  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/78141499-4c41-45e3-b68e-8ff7c43921e1/model.MODULE_317728922451237312+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/78141499-4c41-45e3-b68e-8ff7c43921e1/model.MODULE_317728922451237312+d41d8cd9.neff --verbose=35\n",
      ".\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656,\n",
       "         0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656,\n",
       "         0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656,\n",
       "         0.2656, 0.2656, 0.2656, 0.2656, 0.2656],\n",
       "        [0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656,\n",
       "         0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656,\n",
       "         0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656, 0.2656,\n",
       "         0.2656, 0.2656, 0.2656, 0.2656, 0.2656]], device='xla:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SwiGLU-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch_xla.core.xla_model as xm\n",
    "class Params:\n",
    "    te_device = xm.xla_device()\n",
    "    dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwiGLUTorch(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, args: Params = Params, bias=True):\n",
    "        super().__init__()\n",
    "        self.w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias, device=args.te_device)\n",
    "        # self.w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias)\n",
    "        self.w3 = nn.Linear(hidden_dim, out_dim, bias=bias, device=args.te_device)\n",
    "        # self.w3 = nn.Linear(hidden_dim, out_dim, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate, x = self.w12(x).chunk(2, dim=-1)\n",
    "        x = F.silu(gate) * x\n",
    "        return self.w3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Params()\n",
    "hidden_dim = 256 * ((int(2 * 4 * args.dim / 3) + 256 - 1) // 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed_forward = SwiGLUTorch(args.dim, hidden_dim, args.dim, bias=False)\n",
    "feed_forward = SwiGLUTorch(args.dim, hidden_dim, args.dim, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.rand(2, args.dim, device=args.te_device, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_res = feed_forward(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:17:43.000223:  264768  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:17:43.000225:  264768  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/f6e4c1d2-3346-42ea-97c4-4f33504117cd/model.MODULE_13096779559885804376+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/f6e4c1d2-3346-42ea-97c4-4f33504117cd/model.MODULE_13096779559885804376+d41d8cd9.neff --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "tensor([[-5.4396e-02,  2.4788e-03, -3.6057e-02, -1.0108e-01, -1.1356e-02,\n",
      "          2.1630e-01,  5.1195e-02,  2.5060e-02, -1.2509e-02, -2.9625e-02,\n",
      "         -1.6905e-02, -8.6524e-03,  8.2070e-02, -1.3243e-02,  5.1400e-02,\n",
      "          1.2978e-02, -8.5661e-02, -1.2061e-02,  1.2263e-02, -6.8452e-02,\n",
      "         -5.0165e-02,  3.9816e-02,  4.1906e-02, -1.1900e-01, -1.8282e-02,\n",
      "          6.6551e-03,  2.8953e-02,  1.3302e-02,  1.0320e-01,  1.7242e-02,\n",
      "         -4.8870e-02, -5.7309e-02,  3.0372e-02, -8.2271e-02, -1.1382e-03,\n",
      "          8.1762e-02,  7.9631e-02, -4.7795e-03, -1.7675e-02, -1.9920e-02,\n",
      "         -1.5851e-02, -7.7713e-04,  5.1037e-03, -4.3835e-02, -1.7313e-03,\n",
      "          2.7527e-03, -1.2865e-01, -4.2344e-02, -8.6313e-02, -4.5887e-02,\n",
      "         -7.7144e-02,  2.5151e-02, -5.3777e-02,  7.1058e-02,  7.8367e-02,\n",
      "          5.2203e-02, -7.2707e-02,  1.5272e-02, -2.1821e-02, -1.0093e-02,\n",
      "         -6.2742e-02, -8.1296e-02,  3.6875e-02,  1.4001e-02],\n",
      "        [-6.0170e-02, -2.1390e-02, -3.5301e-02, -8.1397e-03, -5.9280e-04,\n",
      "          9.2743e-02,  4.0837e-02, -3.6541e-02, -2.1321e-02, -3.0524e-02,\n",
      "         -5.5957e-02,  1.3168e-02,  5.3979e-02, -3.8231e-03,  6.9416e-03,\n",
      "          1.8016e-02, -3.4578e-02, -8.8645e-03,  6.2017e-03, -1.8485e-02,\n",
      "         -4.4248e-02,  3.1927e-02, -3.4785e-02, -6.0712e-02,  2.9858e-05,\n",
      "          5.9383e-02,  6.0506e-02,  5.3251e-02,  3.4022e-02,  4.7258e-03,\n",
      "         -2.3585e-02, -4.8863e-02,  2.8277e-02,  1.2446e-02,  5.5191e-02,\n",
      "          7.4914e-02,  7.4106e-02, -1.0546e-02, -2.5671e-02, -6.0683e-02,\n",
      "         -1.8857e-02,  2.7136e-02, -2.0723e-02,  3.0882e-02, -6.4444e-02,\n",
      "          3.9917e-04, -5.2631e-02, -3.0724e-02, -8.8617e-02, -4.5381e-02,\n",
      "         -1.1280e-02, -2.5595e-02, -1.6588e-02,  2.8029e-02,  1.0146e-01,\n",
      "          1.0246e-02, -6.1897e-02,  1.5295e-02, -6.1482e-03, -2.8196e-02,\n",
      "         -8.8946e-02, -5.4503e-02,  3.1825e-02,  4.8745e-03]], device='xla:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First minimal block - confirmed bug existed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:21:43.000300:  264768  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:21:43.000302:  264768  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/d3665e76-36fc-4959-81cc-21acafe435a9/model.MODULE_15793982884432442560+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/d3665e76-36fc-4959-81cc-21acafe435a9/model.MODULE_15793982884432442560+d41d8cd9.neff --verbose=35\n",
      ".\n",
      "Compiler status PASS\n",
      "tensor([[ 0.0041,  0.0943, -0.0168,  0.0420, -0.0077,  0.0305, -0.0181,  0.0230,\n",
      "         -0.0666, -0.0475, -0.0149,  0.0162, -0.0127,  0.0305, -0.0040,  0.0311,\n",
      "         -0.0414, -0.1199, -0.0031, -0.0465,  0.0716, -0.0505, -0.0013, -0.0252,\n",
      "         -0.0435, -0.0330, -0.0317, -0.0164,  0.0551, -0.0207, -0.0724, -0.0230,\n",
      "          0.0215, -0.0102, -0.0254,  0.0936,  0.0846,  0.0255,  0.0509, -0.0537,\n",
      "         -0.0049,  0.0553, -0.0336, -0.0329, -0.0538,  0.0217,  0.0841, -0.0208,\n",
      "          0.0110, -0.0219, -0.0235, -0.0174, -0.0643, -0.0739, -0.0518,  0.0979,\n",
      "          0.0207, -0.0692, -0.0601,  0.0003,  0.0245,  0.0389,  0.0544,  0.0928],\n",
      "        [ 0.0262,  0.0959, -0.0118, -0.0084,  0.0285, -0.0084,  0.0079, -0.0306,\n",
      "         -0.0629, -0.0543,  0.0009,  0.0084,  0.0425, -0.0310,  0.0742,  0.0108,\n",
      "         -0.0041, -0.1179,  0.0056, -0.0739,  0.0185,  0.0002,  0.0131,  0.0051,\n",
      "          0.0553, -0.0336,  0.0083, -0.0349,  0.0406,  0.0747, -0.0150,  0.0320,\n",
      "         -0.0129, -0.0415,  0.0203,  0.0321,  0.0994,  0.0543,  0.0125, -0.0603,\n",
      "         -0.0287,  0.0397, -0.0234,  0.0204,  0.0084,  0.0022,  0.1035,  0.0199,\n",
      "         -0.0304, -0.0949, -0.0401, -0.0511,  0.0007, -0.0610, -0.0304,  0.0530,\n",
      "          0.0349, -0.0339, -0.0257, -0.0178,  0.0898,  0.0818,  0.0918,  0.0817]],\n",
      "       device='xla:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch_xla.core.xla_model as xm\n",
    "class Params:\n",
    "    te_device = xm.xla_device()\n",
    "    dim = 64\n",
    "\n",
    "\n",
    "class SwiGLUTorch(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, args: Params = Params, bias=True):\n",
    "        super().__init__()\n",
    "        self.w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias, device=args.te_device)\n",
    "        # self.w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias)\n",
    "        self.w3 = nn.Linear(hidden_dim, out_dim, bias=bias, device=args.te_device)\n",
    "        # self.w3 = nn.Linear(hidden_dim, out_dim, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate, x = self.w12(x).chunk(2, dim=-1)\n",
    "        x = F.silu(gate) * x\n",
    "        return self.w3(x)\n",
    "\n",
    "\n",
    "args = Params()\n",
    "hidden_dim = 256 * ((int(2 * 4 * args.dim / 3) + 256 - 1) // 256)\n",
    "\n",
    "# feed_forward = SwiGLUTorch(args.dim, hidden_dim, args.dim, bias=False)\n",
    "feed_forward = SwiGLUTorch(args.dim, hidden_dim, args.dim, bias=True)\n",
    "\n",
    "input_data = torch.rand(2, args.dim, device=args.te_device, requires_grad=True)\n",
    "\n",
    "out_res = feed_forward(input_data)\n",
    "\n",
    "print(out_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:21:58.000089:  264768  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:21:58.000091:  264768  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/db98c2ca-6d7e-4c6a-bac7-1709e056f91e/model.MODULE_12445586597400423240+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/db98c2ca-6d7e-4c6a-bac7-1709e056f91e/model.MODULE_12445586597400423240+d41d8cd9.neff --verbose=35\n",
      ".root = /usr/lib/python3.10/multiprocessing/process.py\n",
      "root = /usr/lib/python3.10/multiprocessing\n",
      "root = /usr/lib/python3.10\n",
      "root = /usr/lib\n",
      "root = /usr\n",
      "\n",
      "2024-07-02 16:22:00.000153:  264768  ERROR ||NEURON_CC_WRAPPER||: Failed compilation with ['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/db98c2ca-6d7e-4c6a-bac7-1709e056f91e/model.MODULE_12445586597400423240+d41d8cd9.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/db98c2ca-6d7e-4c6a-bac7-1709e056f91e/model.MODULE_12445586597400423240+d41d8cd9.neff', '--verbose=35']: 2024-07-02T16:21:59Z [TEN404] Internal tensorizer error - Please open a support ticket at https://github.com/aws-neuron/aws-neuron-sdk/issues/new\n",
      "\n",
      "2024-07-02 16:22:00.000154:  264768  ERROR ||NEURON_CC_WRAPPER||: Compilation failed for /tmp/ubuntu/neuroncc_compile_workdir/db98c2ca-6d7e-4c6a-bac7-1709e056f91e/model.MODULE_12445586597400423240+d41d8cd9.hlo_module.pb after 0 retries.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch_xla.core.xla_model as xm\n",
    "class Params:\n",
    "    te_device = xm.xla_device()\n",
    "    dim = 64\n",
    "\n",
    "\n",
    "class SwiGLUTorch(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, args: Params = Params, bias=True):\n",
    "        super().__init__()\n",
    "        self.w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias, device=args.te_device)\n",
    "        # self.w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias)\n",
    "        self.w3 = nn.Linear(hidden_dim, out_dim, bias=bias, device=args.te_device)\n",
    "        # self.w3 = nn.Linear(hidden_dim, out_dim, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate, x = self.w12(x).chunk(2, dim=-1)\n",
    "        x = F.silu(gate) * x\n",
    "        return self.w3(x)\n",
    "\n",
    "\n",
    "args = Params()\n",
    "hidden_dim = 256 * ((int(2 * 4 * args.dim / 3) + 256 - 1) // 256)\n",
    "\n",
    "feed_forward = SwiGLUTorch(args.dim, hidden_dim, args.dim, bias=False)\n",
    "# feed_forward = SwiGLUTorch(args.dim, hidden_dim, args.dim, bias=True)\n",
    "\n",
    "input_data = torch.rand(2, args.dim, device=args.te_device, requires_grad=True)\n",
    "\n",
    "out_res = feed_forward(input_data)\n",
    "\n",
    "print(out_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize the block - bias=False to identify the buggy place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch_xla.core.xla_model as xm\n",
    "class Params:\n",
    "    te_device = xm.xla_device()\n",
    "    dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:50:44.000372:  272458  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:50:44.000374:  272458  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.13.72.0+78a426937/MODULE_4744642293627985264+d41d8cd9/model.neff. Exiting with a successfully compiled graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0384, device='xla:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "args = Params()\n",
    "in_dim = args.dim\n",
    "hidden_dim = 256 * ((int(2 * 4 * args.dim / 3) + 256 - 1) // 256)\n",
    "out_dim = args.dim\n",
    "\n",
    "bias = False\n",
    "\n",
    "w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias, device=args.te_device)\n",
    "# w3 = nn.Linear(hidden_dim, out_dim, bias=bias, device=args.te_device)\n",
    "\n",
    "input_data = torch.rand(2, args.dim, device=args.te_device, requires_grad=True)\n",
    "x = input_data\n",
    "\n",
    "# Feed forward\n",
    "gate, x = w12(x).chunk(2, dim=-1)\n",
    "# x = F.silu(gate) * x\n",
    "# out_res = w3(x)\n",
    "\n",
    "print(x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gate res: 2024-07-02 16:50:48.000018:  272458  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:50:48.000019:  272458  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.13.72.0+78a426937/MODULE_12577992882644976145+d41d8cd9/model.neff. Exiting with a successfully compiled graph.\n",
      "tensor(-0.0107, device='xla:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = input_data\n",
    "gate, x = w12(x).chunk(2, dim=-1)\n",
    "gate_res = F.silu(gate)\n",
    "print(\"gate res:\", gate_res[0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_res_before_w3:  2024-07-02 16:51:08.000672:  272458  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:51:08.000674:  272458  ERROR ||NEURON_CC_WRAPPER||: Got a cached failed neff at /var/tmp/neuron-compile-cache/neuronxcc-2.13.72.0+78a426937/MODULE_2625073130775174431+d41d8cd9/model.neff. Will skip compilation, please set --retry_failed_compilation for recompilation: \n",
      " Failed compilation with ['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/d80981b3-de32-4fcc-be1e-732b7040a871/model.MODULE_2625073130775174431+d41d8cd9.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/d80981b3-de32-4fcc-be1e-732b7040a871/model.MODULE_2625073130775174431+d41d8cd9.neff', '--verbose=35']: 2024-07-02T16:47:45Z [TEN404] Internal tensorizer error - Please open a support ticket at https://github.com/aws-neuron/aws-neuron-sdk/issues/new\n",
      ".\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "out_res_before_w3 = gate_res * x \n",
    "print(\"out_res_before_w3: \", out_res_before_w3[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_res_before_w3:  2024-07-02 16:46:29.000051:  270941  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:46:29.000053:  270941  ERROR ||NEURON_CC_WRAPPER||: Got a cached failed neff at /var/tmp/neuron-compile-cache/neuronxcc-2.13.72.0+78a426937/MODULE_8565120681103738836+d41d8cd9/model.neff. Will skip compilation, please set --retry_failed_compilation for recompilation: \n",
      " Failed compilation with ['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/05bf30d1-52e9-4c44-a2c2-e0ac53702dc3/model.MODULE_8565120681103738836+d41d8cd9.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/05bf30d1-52e9-4c44-a2c2-e0ac53702dc3/model.MODULE_8565120681103738836+d41d8cd9.neff', '--verbose=35']: 2024-07-02T16:42:51Z [TEN404] Internal tensorizer error - Please open a support ticket at https://github.com/aws-neuron/aws-neuron-sdk/issues/new\n",
      ".\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x = input_data\n",
    "gate, x = w12(x).chunk(2, dim=-1)\n",
    "\n",
    "out_res_before_w3 = F.silu(gate) * x \n",
    "print(\"out_res_before_w3: \", out_res_before_w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias=True works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:29:10.000899:  265991  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:29:10.000901:  265991  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/f1a59657-c2bd-48df-9266-c98d0fb02d6a/model.MODULE_13130582528755289296+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/f1a59657-c2bd-48df-9266-c98d0fb02d6a/model.MODULE_13130582528755289296+d41d8cd9.neff --verbose=35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Compiler status PASS\n",
      "tensor([[ 0.0795,  0.0199,  0.0098,  0.0036, -0.0297,  0.0439,  0.0641,  0.0479,\n",
      "         -0.0463, -0.0331, -0.0226,  0.0218, -0.0594, -0.0714, -0.0943, -0.0110,\n",
      "          0.0381,  0.0193, -0.0253, -0.0070, -0.0219,  0.0099,  0.0808, -0.0022,\n",
      "         -0.0886, -0.0090, -0.0910, -0.0522,  0.0207,  0.0209,  0.0953,  0.0139,\n",
      "         -0.0214, -0.0464,  0.0444,  0.0960, -0.0146,  0.0019, -0.0395, -0.1116,\n",
      "          0.0116,  0.0529,  0.0819,  0.0291,  0.0415,  0.0611,  0.0124,  0.0138,\n",
      "         -0.0146, -0.0398,  0.0770,  0.0370,  0.0348,  0.0694,  0.0095, -0.0007,\n",
      "          0.0115,  0.0397,  0.0618, -0.0070, -0.0072,  0.0444,  0.0352,  0.0056],\n",
      "        [ 0.0760, -0.0689, -0.0169,  0.0469, -0.0192,  0.0050,  0.0377,  0.0061,\n",
      "         -0.0644, -0.0557, -0.0811,  0.0475,  0.0372, -0.0131, -0.0621, -0.0388,\n",
      "         -0.0027,  0.0351, -0.0085,  0.0346,  0.0186,  0.0548,  0.0062, -0.0252,\n",
      "         -0.0514, -0.0633, -0.0997, -0.0211,  0.0526,  0.0092,  0.0654,  0.0114,\n",
      "         -0.0215, -0.0839,  0.0131,  0.0583,  0.0273,  0.0406, -0.0226, -0.0656,\n",
      "         -0.0132,  0.0742,  0.0416,  0.0605,  0.0540,  0.0509, -0.0316,  0.0549,\n",
      "          0.0126, -0.0299,  0.0242, -0.0057,  0.0785,  0.0637,  0.0381, -0.0118,\n",
      "         -0.0002,  0.0158, -0.0016,  0.0321,  0.0617,  0.0183,  0.0553,  0.0292]],\n",
      "       device='xla:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Works fine\n",
    "args = Params()\n",
    "in_dim = args.dim\n",
    "hidden_dim = 256 * ((int(2 * 4 * args.dim / 3) + 256 - 1) // 256)\n",
    "out_dim = args.dim\n",
    "\n",
    "bias = True\n",
    "\n",
    "w12 = nn.Linear(in_dim, 2 * hidden_dim, bias=bias, device=args.te_device)\n",
    "w3 = nn.Linear(hidden_dim, out_dim, bias=bias, device=args.te_device)\n",
    "\n",
    "\n",
    "\n",
    "input_data = torch.rand(2, args.dim, device=args.te_device, requires_grad=True)\n",
    "x = input_data\n",
    "\n",
    "# Feed forward\n",
    "gate, x = w12(x).chunk(2, dim=-1)\n",
    "x = F.silu(gate) * x\n",
    "out_res = w3(x)\n",
    "\n",
    "\n",
    "print(out_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 16:30:58.000386:  266572  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-07-02 16:30:58.000388:  266572  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/5a269232-1341-4dc8-b8e1-0825636dc043/model.MODULE_5261249125463362669+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/5a269232-1341-4dc8-b8e1-0825636dc043/model.MODULE_5261249125463362669+d41d8cd9.neff --verbose=35\n",
      ".root = /usr/lib/python3.10/multiprocessing/process.py\n",
      "root = /usr/lib/python3.10/multiprocessing\n",
      "root = /usr/lib/python3.10\n",
      "root = /usr/lib\n",
      "root = /usr\n",
      "\n",
      "2024-07-02 16:31:00.000300:  266572  ERROR ||NEURON_CC_WRAPPER||: Failed compilation with ['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/5a269232-1341-4dc8-b8e1-0825636dc043/model.MODULE_5261249125463362669+d41d8cd9.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/5a269232-1341-4dc8-b8e1-0825636dc043/model.MODULE_5261249125463362669+d41d8cd9.neff', '--verbose=35']: 2024-07-02T16:31:00Z [TEN404] Internal tensorizer error - Please open a support ticket at https://github.com/aws-neuron/aws-neuron-sdk/issues/new\n",
      "\n",
      "2024-07-02 16:31:00.000301:  266572  ERROR ||NEURON_CC_WRAPPER||: Compilation failed for /tmp/ubuntu/neuroncc_compile_workdir/5a269232-1341-4dc8-b8e1-0825636dc043/model.MODULE_5261249125463362669+d41d8cd9.hlo_module.pb after 0 retries.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuronx_venv_pytorch_2_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
